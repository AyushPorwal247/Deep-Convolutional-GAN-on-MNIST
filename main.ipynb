{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading and Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imageio) (1.23.5)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imageio) (9.4.0)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# For generating GIF of result\n",
    "!pip install imageio\n",
    "!pip install git+https://github.com/tensorflow/docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "(x_train, y_train), (_,_) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#Reshaping and Normalising training data\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "#Normalising between [-1,1]\n",
    "x_train = (x_train-127.5)/127.5\n",
    "\n",
    "#Setting BATCH_SIZE and BUFFER_SIZE\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "#Shuffling and dividing data in batches\n",
    "x_train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense((7*7*256), use_bias = False, input_shape = (100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Our Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to c:\\users\\ayush\\appdata\\local\\temp\\pip-req-build-56vkqatu\n",
      "  Resolved https://github.com/tensorflow/docs to commit ba879887790ded183c04540d5386df4962f48eeb\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: astor in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-docs==0.0.0.dev0) (1.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
      "Requirement already satisfied: protobuf>=3.12 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-docs==0.0.0.dev0) (4.22.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (2.6.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (305)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\ayush\\AppData\\Local\\Temp\\pip-req-build-56vkqatu'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e41cd7b10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_model = generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = gen_model(noise, training = False)\n",
    "\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.axis(False)\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Discriminator Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5,5), strides = (2,2), padding = 'same', input_shape = [28,28,1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5,5), strides = (2,2), padding = 'same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Disciminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00276198]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dis_model = discriminator_model()\n",
    "print(dis_model(generated_image))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and Loss and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Discriminator Loss\n",
    "def dis_loss(real, fake):\n",
    "    real_set_loss = loss(tf.ones_like(real), real)\n",
    "    fake_set_loss = loss(tf.zeros_like(fake), fake)\n",
    "    total_loss = real_set_loss + fake_set_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Generator Loss\n",
    "def gen_loss(fake):\n",
    "    return loss(tf.ones_like(fake), fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Optimizers\n",
    "gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "dis_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100 \n",
    "images = 16\n",
    "\n",
    "seed = tf.random.normal([images, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = gen_model(noise, training=True)\n",
    "\n",
    "      real_output = dis_model(images, training=True)\n",
    "      fake_output = dis_model(generated_images, training=True)\n",
    "\n",
    "      generator_loss = gen_loss(fake_output)\n",
    "      discriminator_loss = dis_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(generator_loss, gen_model.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(discriminator_loss, dis_model.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_generator, gen_model.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(gradients_of_discriminator, dis_model.trainable_variables))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating and Saving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(model, epoch, input):\n",
    "    predictions = model(input, training = False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
